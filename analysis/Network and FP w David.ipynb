{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import glob\n",
    "import os\n",
    "import pdb\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import json\n",
    "import getpass\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "from numpy import linalg as LA\n",
    "import numpy.random as npr\n",
    "from sklearn.decomposition import PCA\n",
    "import imageio\n",
    "\n",
    "ui = getpass.getuser()\n",
    "if ui == 'laura':\n",
    "    p = '/home/laura'\n",
    "elif ui == 'lauradriscoll':\n",
    "    p = '/Users/lauradriscoll/Documents'\n",
    "elif ui == 'lndrisco':\n",
    "    p = '/home/users/lndrisco'\n",
    "\n",
    "net = 'stepnet'\n",
    "PATH_YANGNET = os.path.join(p,'code/multitask-nets',net)\n",
    "\n",
    "sys.path.insert(0, PATH_YANGNET)\n",
    "from task import generate_trials, rule_name, rule_index_map, rules_dict\n",
    "from network import Model\n",
    "import tools\n",
    "from tools_lnd import make_axes, name_best_ckpt, generate_Beta_epoch, make_h_combined, same_stim_trial\n",
    "from tools_lnd import get_T_inds\n",
    "\n",
    "PATH_TO_RECURRENT_WHISPERER = p+'/code/recurrent-whisperer'#'/home/laura/code/recurrent-whisperer'#\n",
    "sys.path.insert(0, PATH_TO_RECURRENT_WHISPERER)\n",
    "from RecurrentWhisperer import RecurrentWhisperer\n",
    "\n",
    "PATH_TO_FIXED_POINT_FINDER = p+'/code/fixed-point-finder' #'/home/laura/code/fixed-point-finder-experimental'#\n",
    "sys.path.insert(0, PATH_TO_FIXED_POINT_FINDER)\n",
    "from FixedPointFinder import FixedPointFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables being optimized:\n",
      "<tf.Variable 'rnn/leaky_rnn_cell/kernel:0' shape=(281, 256) dtype=float32_ref>\n",
      "<tf.Variable 'rnn/leaky_rnn_cell/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'output/weights:0' shape=(256, 3) dtype=float32_ref>\n",
      "<tf.Variable 'output/biases:0' shape=(3,) dtype=float32_ref>\n",
      "INFO:tensorflow:Restoring parameters from /Users/lauradriscoll/Documents/data/rnn/multitask/crystals/softplus/l2w0001/0/ckpts/model.ckpt-270000\n"
     ]
    }
   ],
   "source": [
    "rule = 'delaygo'\n",
    "model_n = 0\n",
    "dir_specific_all = 'crystals/softplus/l2w0001'#'crystals/softplus/l2h00001'#'crystals/softplus/no_reg'#s'crystals/softplus/l2h00001'#'tepnet/crystals/softplus/'#grad_norm_both/'#'lowD/combos'#'stepnet/lowD/tanh'#'lowD/grad_norm_l2001' #' #'lowD/armnet_noreg'#lowD/combos' ##grad_norm_l2h000001' /Documents/data/rnn/multitask/varGo/lowD/most/\n",
    "model_dir_all = os.path.join(p,'data/rnn/multitask/',dir_specific_all,str(model_n))\n",
    "ckpt_n = name_best_ckpt(model_dir_all,rule)\n",
    "ckpt_n_dir = os.path.join(model_dir_all,'ckpts/model.ckpt-' + str(int(ckpt_n)))\n",
    "\n",
    "model = Model(model_dir_all)\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    model.saver.restore(sess,ckpt_n_dir)\n",
    "    # get all connection weights and biases as tensorflow variables\n",
    "    var_list = model.var_list\n",
    "    # evaluate the parameters after training\n",
    "    params = [sess.run(var) for var in var_list]\n",
    "    # get hparams\n",
    "    hparams = model.hp\n",
    "    trial_master = generate_trials(rule, hparams, mode = 'random', batch_size = 100, noise_on=True, delay_fac =1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = hparams['tau']\n",
    "dt = hparams['dt']\n",
    "print(tau,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "#Run fixed pt finder\n",
    "##################################################################\n",
    "def project2d(x,axes):\n",
    "\n",
    "    if x.ndim>1:\n",
    "        n_steps = x.shape[1]\n",
    "    else:\n",
    "        n_steps = 1\n",
    "\n",
    "    z = np.zeros((n_steps,2))\n",
    "    z[:,0] = np.dot(axes[:,0],x)\n",
    "    z[:,1] = np.dot(axes[:,1],x)\n",
    "    return z\n",
    "\n",
    "def add_unique_to_inputs_list(dict_list, key, value):\n",
    "    for d in range(len(dict_list)):\n",
    "        if (dict_list.values()[d]==value).all():\n",
    "            return False, dict_list\n",
    "\n",
    "    dict_list.update({key : value})\n",
    "    return True, dict_list\n",
    "\n",
    "def get_filename(trial, epoch,t):\n",
    "    filename = trial.epochs.keys()[epoch]+'_'+str(t)\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables being optimized:\n",
      "<tf.Variable 'rnn/leaky_rnn_cell/kernel:0' shape=(281, 256) dtype=float32_ref>\n",
      "<tf.Variable 'rnn/leaky_rnn_cell/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'output/weights:0' shape=(256, 3) dtype=float32_ref>\n",
      "<tf.Variable 'output/biases:0' shape=(3,) dtype=float32_ref>\n",
      "INFO:tensorflow:Restoring parameters from /Users/lauradriscoll/Documents/data/rnn/multitask/crystals/softplus/l2w0001/0/model.ckpt\n",
      "Model restored from file: /Users/lauradriscoll/Documents/data/rnn/multitask/crystals/softplus/l2w0001/0/model.ckpt\n",
      "\n",
      "Warning: sample_states is deprecated and will be removed in a future version--use sample_inputs_and_states instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Trying to access flag --op_conversion_fallback_to_while_loop before flags were parsed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tinitial_states: 0 outliers detected (of 500).\n",
      "\t\tfixed points: 0 outliers detected (of 28).\n",
      "\tDecomposing Jacobians in a single batch.\n",
      "\tSorting by Eigenvalue magnitude.\n"
     ]
    }
   ],
   "source": [
    "task_list = ['reactgo']\n",
    "NOISE_SCALE = 0.05 #0.01 #0.5 # Standard deviation of noise added to initial states\n",
    "N_INITS = 500 # The number of initial states to provide\n",
    "\n",
    "for rule in task_list:\n",
    "    model = Model(model_dir_all)\n",
    "    with tf.Session() as sess:\n",
    "        model.restore()\n",
    "        model._sigma=0\n",
    "        # get all connection weights and biases as tensorflow variables\n",
    "        var_list = model.var_list\n",
    "        # evaluate the parameters after training\n",
    "        params = [sess.run(var) for var in var_list]\n",
    "        # get hparams\n",
    "        hparams = model.hp\n",
    "        # create a trial\n",
    "        trial = generate_trials(rule, hparams, mode='test', noise_on=False, batch_size=40, delay_fac = 1)# get feed_dict\n",
    "        feed_dict = tools.gen_feed_dict(model, trial, hparams)\n",
    "        # run model\n",
    "        h_tf, y_hat_tf = sess.run([model.h, model.y_hat], feed_dict=feed_dict) #(n_time, n_condition, n_neuron)  \n",
    "\n",
    "        ##################################################################\n",
    "        # get shapes   \n",
    "        n_steps, n_trials, n_input_dim = np.shape(trial.x)\n",
    "        n_rnn = np.shape(h_tf)[2]\n",
    "        n_output = np.shape(y_hat_tf)[2]\n",
    "\n",
    "        fpf_hps = {}\n",
    "        alr_dict = ({'decrease_factor' : .95, 'initial_rate' : 1})\n",
    "\n",
    "        n_epochs = len(trial.epochs)\n",
    "        for epoch in [1,]:#range(n_epochs):\n",
    "            e_start = max([0, trial.epochs.values()[epoch][0]])\n",
    "            end_set = [n_steps, trial.epochs.values()[epoch][1]]\n",
    "            e_end = min(x for x in end_set if x is not None)\n",
    "\n",
    "            n_inputs = 0\n",
    "            input_set = {str(n_inputs) : np.zeros((1,n_input_dim))}\n",
    "\n",
    "            for t in range(0,n_trials,n_trials):#range(1,n_trials): np.arange(0, 40, 8): #\n",
    "\n",
    "                inputs = np.squeeze(trial.x[e_start,t,:])\n",
    "                inputs = inputs[np.newaxis,:]\n",
    "                inputs_big = inputs[np.newaxis,:]\n",
    "\n",
    "                unique_input, input_set = add_unique_to_inputs_list(input_set, str(n_inputs), inputs)\n",
    "                \n",
    "                if unique_input:\n",
    "                    n_inputs+=1\n",
    "                    input_set[str(n_inputs)] = inputs\n",
    "\n",
    "                    fpf = []\n",
    "                    fpf = FixedPointFinder(model.cell,sess, alr_hps=alr_dict, method='joint', verbose = False, **fpf_hps) #do_compute_input_jacobians = True , q_tol = 1e-1, do_q_tol = True\n",
    "\n",
    "                    example_predictions = {'state': np.transpose(h_tf,(1,0,2)), #[0:90,0:1,:]\n",
    "                                            'output': np.transpose(y_hat_tf,(1,0,2))}\n",
    "                    \n",
    "                    initial_states = fpf.sample_states(example_predictions['state'][:,e_start:e_end,:],\n",
    "                                                    n_inits=N_INITS,\n",
    "                                                    noise_scale=NOISE_SCALE)\n",
    "\n",
    "                    unique_fps, all_fps = fpf.find_fixed_points(initial_states, inputs)\n",
    "\n",
    "\n",
    "                    if unique_fps.xstar.shape[0]>0:\n",
    "\n",
    "                        save_dir = os.path.join(model_dir_all,'troubleshoot_fixed_pts',rule)#,'random_trials'\n",
    "                        filename = get_filename(trial, epoch, t)\n",
    "                        all_fps = {}\n",
    "                        all_fps = {'xstar':unique_fps.xstar,\n",
    "                            'J_xstar':unique_fps.J_xstar, \n",
    "                            'qstar':unique_fps.qstar, \n",
    "                            'inputs':unique_fps.inputs, \n",
    "                            'epoch_inds':range(e_start,e_end),\n",
    "                            'noise_var':NOISE_SCALE,\n",
    "                            'trial_num':t,\n",
    "                            'state_traj':example_predictions['state']}\n",
    "\n",
    "                        if not os.path.exists(save_dir):\n",
    "                            os.makedirs(save_dir)\n",
    "                        np.savez(os.path.join(save_dir,filename+'.npz'),**all_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_eig_decomp(Ms, sort_by='real',\n",
    "                                     do_compute_lefts=True):\n",
    "  \"\"\"Compute the eigenvalues of the matrix M. No assumptions are made on M.\n",
    "\n",
    "  Arguments: \n",
    "    M: 3D np.array nmatrices x dim x dim matrix\n",
    "    do_compute_lefts: Compute the left eigenvectors? Requires a pseudo-inverse \n",
    "      call.\n",
    "\n",
    "  Returns: \n",
    "    list of dictionaries with eigenvalues components: sorted \n",
    "      eigenvalues, sorted right eigenvectors, and sored left eigenvectors \n",
    "      (as column vectors).\n",
    "  \"\"\"\n",
    "  if sort_by == 'magnitude':\n",
    "    sort_fun = np.abs\n",
    "  elif sort_by == 'real':\n",
    "    sort_fun = np.real\n",
    "  else:\n",
    "    assert False, \"Not implemented yet.\"      \n",
    "  \n",
    "  decomps = []\n",
    "  L = None  \n",
    "  for M in Ms:\n",
    "    evals, R = LA.eig(M)    \n",
    "    indices = np.flipud(np.argsort(sort_fun(evals)))\n",
    "    if do_compute_lefts:\n",
    "      L = LA.pinv(R).T  # as columns      \n",
    "      L = L[:, indices]\n",
    "    decomps.append({'evals' : evals[indices], 'R' : R[:, indices],  'L' : L})\n",
    "  \n",
    "  return decomps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_FP(X, D, eig_decomps, c='k'):\n",
    "    \"\"\"Plot activity is some 2D space.\n",
    "\n",
    "        Args:\n",
    "            X: Fixed points in #Fps x Neurons\n",
    "            D: Neurons x 2 plotting dims\n",
    "    \n",
    "        \"\"\"\n",
    "    S = np.shape(X)[0]\n",
    "    lf = 1\n",
    "    rf = 1\n",
    "    \n",
    "    for s in range(S):\n",
    "        \n",
    "        X_trial = np.dot(X[s,:],D.T)\n",
    "        \n",
    "        n_arg = np.argwhere(eig_decomps[s]['evals']>1)+1\n",
    "        if len(n_arg)>0:\n",
    "            for arg in range(np.max(n_arg)):\n",
    "                rdots = np.dot(np.real(eig_decomps[s]['R'][:, arg]).T,D.T)\n",
    "                ldots = np.dot(np.real(eig_decomps[s]['L'][:, arg]).T,D.T)\n",
    "                overlap = np.dot(rdots,ldots.T)\n",
    "                r = np.concatenate((X_trial - rf*overlap*rdots, X_trial + rf*overlap*rdots),0)\n",
    "                plt.plot(r[0:4:2],r[1:4:2],'k',alpha = .5,linewidth = .5)\n",
    "        \n",
    "        n_arg = np.argwhere(eig_decomps[s]['evals']<.3)\n",
    "        if len(n_arg)>0:\n",
    "            for arg in range(np.min(n_arg),len(eig_decomps[s]['evals'])):\n",
    "                rdots = np.dot(np.real(eig_decomps[s]['R'][:, arg]).T,D.T)\n",
    "                ldots = np.dot(np.real(eig_decomps[s]['L'][:, arg]).T,D.T)\n",
    "                overlap = np.dot(rdots,ldots.T)\n",
    "                r = np.concatenate((X_trial - rf*overlap*rdots, X_trial + rf*overlap*rdots),0)\n",
    "                plt.plot(r[0:4:2],r[1:4:2],'b',alpha = .5,linewidth = .5)\n",
    "            \n",
    "        plt.plot(X_trial[0], X_trial[1], 'o', markerfacecolor = c, markeredgecolor = 'k', \n",
    "                 markersize = 6, alpha = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
