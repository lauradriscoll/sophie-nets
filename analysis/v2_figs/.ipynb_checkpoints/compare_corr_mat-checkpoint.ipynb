{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import getpass\n",
    "ui = getpass.getuser()\n",
    "if ui == 'laura':\n",
    "    p = '/home/laura'\n",
    "elif ui == 'lauradriscoll':\n",
    "    p = '/Users/lauradriscoll/Documents'\n",
    "\n",
    "net = 'stepnet'\n",
    "PATH_YANGNET = os.path.join(p,'code/multitask-nets',net) \n",
    "\n",
    "sys.path.insert(0, PATH_YANGNET)\n",
    "from network import Model\n",
    "\n",
    "from sklearn.decomposition import FactorAnalysis, PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names_master = ['DNMS fix1', 'DNMC fix1', 'Dly Anti fix1', 'DMC fix1',\n",
    "#        'Ctx Dly DM 2 fix1', 'Anti fix1', 'Dly DM 1 fix1', 'Dly DM 2 fix1',\n",
    "#        'MultSen Dly DM fix1', 'Go fix1', 'Dly Go fix1',\n",
    "#        'Ctx Dly DM 1 fix1', 'DMS fix1', 'RT Go fix1', 'RT Anti fix1',\n",
    "#        'DMS delay1', 'DMS go1', 'Ctx Dly DM 2 go1', 'Ctx Dly DM 1 go1',\n",
    "#        'MultSen Dly DM go1', 'Go go1', 'Dly Go go1', 'Dly DM 1 go1',\n",
    "#        'Dly DM 2 go1', 'Anti go1', 'Anti stim1', 'Ctx Dly DM 2 delay1',\n",
    "#        'Ctx Dly DM 2 delay2', 'Ctx Dly DM 1 delay2',\n",
    "#        'Ctx Dly DM 1 delay1', 'MultSen Dly DM delay1',\n",
    "#        'MultSen Dly DM delay2', 'Dly DM 1 delay1', 'Dly DM 2 delay1',\n",
    "#        'Dly Go delay1', 'Dly DM 1 delay2', 'Dly DM 2 delay2',\n",
    "#        'DMC delay1', 'DNMC delay1', 'Dly Anti delay1', 'Dly Anti go1',\n",
    "#        'DMC stim1', 'Dly Anti stim1', 'Dly Go stim1', 'DMS stim1',\n",
    "#        'MultSen Dly DM stim1', 'MultSen Dly DM stim2', 'Dly DM 2 stim1',\n",
    "#        'Ctx Dly DM 2 stim1', 'Dly DM 2 stim2', 'Ctx Dly DM 2 stim2',\n",
    "#        'Ctx Dly DM 1 stim1', 'Ctx Dly DM 1 stim2', 'Dly DM 1 stim2',\n",
    "#        'Go stim1', 'Dly DM 1 stim1', 'RT Anti go1', 'DNMS go1',\n",
    "#        'RT Go go1', 'DMC go1', 'DNMC go1', 'DNMS delay1', 'DNMS stim1',\n",
    "#        'DNMC stim1']\n",
    "\n",
    "\n",
    "feature_names_master = ['DNMS go1', 'DMS go1', 'RT Go go1', 'DMC go1', 'DNMC go1',\n",
    "       'RT Anti fix1', 'RT Go fix1', 'DNMC fix1', 'Dly DM 1 fix1',\n",
    "       'Ctx Dly DM 1 fix1', 'DNMS fix1', 'DMS fix1', 'Anti fix1',\n",
    "       'Dly Anti fix1', 'DMC fix1', 'Ctx Dly DM 2 fix1', 'Go fix1',\n",
    "       'MultSen Dly DM fix1', 'Dly Go fix1', 'Dly DM 2 fix1',\n",
    "       'Dly Go go1', 'Dly Anti go1', 'Ctx Dly DM 2 go1',\n",
    "       'Ctx Dly DM 1 go1', 'MultSen Dly DM go1', 'Dly DM 1 go1',\n",
    "       'Dly DM 2 go1', 'RT Anti go1', 'Go go1', 'Anti go1', 'Anti stim1',\n",
    "       'Dly Anti stim1', 'Dly DM 1 stim1', 'Go stim1', 'Dly Go stim1',\n",
    "       'Dly DM 2 stim1', 'Ctx Dly DM 1 stim1', 'Ctx Dly DM 2 stim1',\n",
    "       'MultSen Dly DM stim1', 'Dly DM 1 delay2', 'Dly DM 2 delay2',\n",
    "       'Dly Anti delay1', 'Ctx Dly DM 2 delay2', 'Ctx Dly DM 1 delay2',\n",
    "       'MultSen Dly DM delay2', 'Dly Go delay1', 'Ctx Dly DM 1 delay1',\n",
    "       'MultSen Dly DM delay1', 'Dly DM 1 delay1', 'Dly DM 2 delay1',\n",
    "       'Ctx Dly DM 2 delay1', 'DMS stim1', 'DNMS stim1', 'DMC stim1',\n",
    "       'DNMC stim1', 'Dly DM 1 stim2', 'Dly DM 2 stim2',\n",
    "       'Ctx Dly DM 1 stim2', 'Ctx Dly DM 2 stim2', 'MultSen Dly DM stim2',\n",
    "       'DNMS delay1', 'DMS delay1', 'DMC delay1', 'DNMC delay1']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import eye, asarray, dot, sum, diag\n",
    "from numpy.linalg import svd\n",
    "def varimax(Phi, gamma = 1.0, q = 100, tol = 1e-6):\n",
    "    p,k = Phi.shape\n",
    "    R = eye(k)\n",
    "    d=0\n",
    "    for i in xrange(q):\n",
    "        d_old = d\n",
    "        Lambda = dot(Phi, R)\n",
    "        u,s,vh = svd(dot(Phi.T,asarray(Lambda)**3 - (gamma/p) * dot(Lambda, diag(diag(dot(Lambda.T,Lambda))))))\n",
    "        R = dot(u,vh)\n",
    "        d = sum(s)\n",
    "        print(i)\n",
    "        if d_old!=0 and d/d_old < 1 + tol: break\n",
    "    return R, dot(Phi, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spines(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "\n",
    "def remove_ticks(ax):\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "def plot_epoch_labels(ax, which_axes = 'y', ms = 3):\n",
    "    \n",
    "    e_set = ['fix','stim','delay','go']\n",
    "    e_color = ['orange','limegreen','plum','dodgerblue']\n",
    "    \n",
    "    yl = np.max(ax.get_ylim())+2\n",
    "    xl = np.max(ax.get_xlim())+2\n",
    "    \n",
    "    for ei in range(len(e_set)):\n",
    "        e_name = e_set[ei]\n",
    "        c = e_color[ei]\n",
    "        \n",
    "        if 'y' in which_axes:\n",
    "            \n",
    "            ax.plot(np.where(epoch_binary[e_name])[0],\n",
    "                     yl*np.ones(np.sum(epoch_binary[e_name])),'s',\n",
    "                     color = c,markersize = ms,label = e_name)\n",
    "            \n",
    "        if 'x' in which_axes:\n",
    "            \n",
    "            ax.plot(xl*np.ones(np.sum(epoch_binary[e_name])),\n",
    "                     np.where(epoch_binary[e_name])[0],'s',\n",
    "                     color = c,markersize = ms,label = e_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6f88a8ef3985>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m m_master = os.path.join(p,data_folder,rnn_type,activation,w_init,n_tasks+'_tasks',n_rnn+'_n_rnn',\n\u001b[0m\u001b[1;32m      2\u001b[0m                             net_name,seed)\n\u001b[1;32m      3\u001b[0m \u001b[0mlesion_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lesion_fps_hierarchical_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_max_d'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_master\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlesion_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcluster_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cluster_var.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_folder' is not defined"
     ]
    }
   ],
   "source": [
    "m_master = os.path.join(p,data_folder,rnn_type,activation,w_init,n_tasks+'_tasks',n_rnn+'_n_rnn',\n",
    "                            net_name,seed)\n",
    "lesion_folder = 'lesion_fps_hierarchical_'+method+'_max_d'+str(max_d)\n",
    "save_dir = os.path.join(m_master,lesion_folder)\n",
    "cluster_var = np.load(os.path.join(save_dir,'cluster_var.npz'))\n",
    "cluster_var['tick_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/Users/lauradriscoll/Documents/data/rnn/multitask/stepnet/untrained/GRU/softplus/diag/15_tasks/256_n_rnn/lr7.0l2_w6.0_h6.0_fdgo_reactgo_delaygo_fdanti_reactanti_delayanti_delaydm1_delaydm2_contextdelaydm1_contextdelaydm2_multidelaydm_dmsgo_dmsnogo_dmcgo_dmcnogo/0/lesion_fps_hierarchical_ward_max_d3.5/cluster_var.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-007df47db1f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mlesion_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lesion_fps_hierarchical_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_max_d'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_master\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlesion_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mcluster_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cluster_var.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mseed_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lauradriscoll/anaconda2/envs/tensorflow/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/Users/lauradriscoll/Documents/data/rnn/multitask/stepnet/untrained/GRU/softplus/diag/15_tasks/256_n_rnn/lr7.0l2_w6.0_h6.0_fdgo_reactgo_delaygo_fdanti_reactanti_delayanti_delaydm1_delaydm2_contextdelaydm1_contextdelaydm2_multidelaydm_dmsgo_dmsnogo_dmcgo_dmcnogo/0/lesion_fps_hierarchical_ward_max_d3.5/cluster_var.npz'"
     ]
    }
   ],
   "source": [
    "##################################################################\n",
    "#Find right model dir\n",
    "##################################################################\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "method = 'ward'\n",
    "max_d = 3.5\n",
    "sparsity_threshold = .15\n",
    "ex_1 = 1\n",
    "ex_2 = 6\n",
    "ex_3 = 8\n",
    "al = .3\n",
    "seed_set = ['0','1','2']#[str(0),str(1),str(2)]#[str(0),str(1)]\n",
    "\n",
    "rule_trains = ['fdgo', 'reactgo', 'delaygo', 'fdanti', 'reactanti', 'delayanti',\n",
    "          'delaydm1', 'delaydm2', 'contextdelaydm1', 'contextdelaydm2', 'multidelaydm',\n",
    "          'dmsgo', 'dmsnogo', 'dmcgo', 'dmcnogo']\n",
    "\n",
    "rule_trains_str = '_'.join(rule_trains)\n",
    "\n",
    "n_tasks = str(len(rule_trains))\n",
    "n_rnn = str(256)\n",
    "l2w = -6\n",
    "l2h = -6\n",
    "l1w = 0\n",
    "l1h = 0\n",
    "lr = -7\n",
    "net_name = 'lr'+\"{:.1f}\".format(-lr)+'l2_w'+\"{:.1f}\".format(-l2w)+'_h'+\"{:.1f}\".format(-l2h)+'_'+rule_trains_str\n",
    "# data_folder = 'data/rnn/multitask/stepnet/variable_stim_slow_learn_big_noise'\n",
    "data_folder = 'data/rnn/multitask/stepnet/lr' #8/2/21\n",
    "data_folder = 'data/rnn/multitask/stepnet/untrained' #8/2/21\n",
    "\n",
    "# identify master network to compare other networks to. can be chosen randomly\n",
    "rnn_type = 'GRU'\n",
    "activation = 'softplus'\n",
    "w_init = 'diag'\n",
    "\n",
    "label_master = ' '.join([rnn_type,activation,w_init])\n",
    "\n",
    "# load master network and make average correlation matrix across seeds\n",
    "for seed in seed_set:\n",
    "    m_master = os.path.join(p,data_folder,rnn_type,activation,w_init,n_tasks+'_tasks',n_rnn+'_n_rnn',\n",
    "                            net_name,seed)\n",
    "    lesion_folder = 'lesion_fps_hierarchical_'+method+'_'+'distance'+'_max_d'+str(max_d)\n",
    "    save_dir = os.path.join(m_master,lesion_folder)\n",
    "    cluster_var = np.load(os.path.join(save_dir,'cluster_var.npz'))\n",
    "    \n",
    "    if seed==seed_set[0]:\n",
    "        feature_names_master = cluster_var['tick_names']\n",
    "        feature_names = feature_names_master\n",
    "        len_te = len(feature_names_master)\n",
    "        feature_names_labels = [feat_name.rsplit(' ', 1)[0] for feat_name in feature_names_master]\n",
    "        epoch_binary = {}\n",
    "        for e_name in ['fix','delay','go','stim']:\n",
    "            epoch_binary[e_name] = [feat_name.rsplit(' ', 1)[-1][:-1]==e_name for \n",
    "                                    feat_name in feature_names_master]\n",
    "    \n",
    "    D = cluster_var['D'].T\n",
    "    feature_names_original = [cluster_var['tick_names'][s] for s in range(len(cluster_var['tick_names']))]\n",
    "\n",
    "    feat_order = [feature_names_original.index(s) for i,s in enumerate(feature_names_master)]\n",
    "    X = D[:,feat_order]\n",
    "\n",
    "    corr_mat = np.corrcoef(X.T)\n",
    "\n",
    "    if seed==seed_set[0]:\n",
    "        corr_mat_stack = corr_mat[:,np.newaxis]\n",
    "    else:\n",
    "        corr_mat_stack = np.concatenate((corr_mat_stack,corr_mat[:,np.newaxis]),axis=1)\n",
    "\n",
    "corr_mat_master = np.mean(corr_mat_stack,axis = 1)\n",
    "tril_corr_mat_master = corr_mat_master[np.tril_indices(len(corr_mat_master),-1)]\n",
    "\n",
    "print(m_master)\n",
    "\n",
    "#visualize atlas for master network\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "atlas_width = .5\n",
    "atlas_height = .88\n",
    "\n",
    "axdendro = fig.add_axes([0,.145,0.05,.786])\n",
    "Y = sch.linkage(X, method=method)\n",
    "clusters = fcluster(Y, max_d, criterion='distance')\n",
    "Z = sch.dendrogram(Y, orientation='left',#labels = clusters, #CA.ind_active #clusters\n",
    "                   leaf_font_size = 11,color_threshold=5)\n",
    "remove_spines(axdendro)\n",
    "remove_ticks(axdendro)\n",
    "\n",
    "axmatrix = fig.add_axes([.06,0.05,atlas_width-.05,atlas_height])#fig.add_subplot(1,2,1)\n",
    "index_top = Z['leaves']\n",
    "X = X[index_top,:]\n",
    "plt.imshow(X[-1:0:-1,:],cmap= 'magma', aspect='auto')\n",
    "\n",
    "axmatrix.set_xticks(range(len_te))\n",
    "axmatrix.set_xticklabels(feature_names_labels,fontsize = 11.5, rotation =90,ha = 'center')\n",
    "plot_epoch_labels(axmatrix,which_axes = 'y',ms = 10)\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.07))    \n",
    "\n",
    "plt.text(-9,128,'Units (sorted by row dendrogram)',rotation = 90)\n",
    "axmatrix.set_xlabel('Task Periods (sorted by column dendrogram)')\n",
    "axmatrix.xaxis.set_label_coords(.7, -.13)\n",
    "plt.title('Example #1 \\n'+label_master, fontsize = 16)\n",
    "cbar = plt.colorbar(orientation=\"horizontal\",fraction=0.008, pad=0.09,anchor=(-.08,0.0))\n",
    "cbar.set_label('Normalized Variance')\n",
    "remove_spines(axmatrix)\n",
    "axmatrix.set_yticks([])\n",
    "plt.ylim((257,0))\n",
    "\n",
    "# make subpanels.\n",
    "sp_width = .15\n",
    "sp_wide = .25\n",
    "offset = .07\n",
    "perf_ax = fig.add_axes([offset+atlas_width+sp_wide,3*sp_wide,sp_width,sp_width])\n",
    "sparsity_ax = fig.add_axes([offset+atlas_width+sp_wide,2*sp_wide,sp_width,sp_width])\n",
    "corr_ax = fig.add_axes([offset+atlas_width+sp_wide,sp_wide,sp_width,sp_width])\n",
    "corrmatex1 = fig.add_axes([offset+atlas_width,3*sp_wide,sp_width,sp_width])\n",
    "corrmatex2 = fig.add_axes([offset+atlas_width,2*sp_wide,sp_width,sp_width])\n",
    "corrmatex3 = fig.add_axes([offset+atlas_width,sp_wide-.05,sp_width,sp_width+.1])\n",
    "\n",
    "# set of networks to compare\n",
    "rnn_type_set = ['GRU']\n",
    "activation_set = ['softplus']\n",
    "w_init_set = ['diag','randgauss']\n",
    "\n",
    "# for rnn_type in ['GRU','LeakyRNN']: #\n",
    "#     for activation in ['softplus','retanh','tanh']: #\n",
    "#         for init in ['randgauss','diag']:# \n",
    "#             for seed in ['0','1','2']: #['untrained',]:\n",
    "\n",
    "# x-axis for plotting each networks correlation coeff, sparsity, performance\n",
    "x_ind_counter = 0\n",
    "ax1_xticks = []\n",
    "\n",
    "for rnn_type_i in range(len(rnn_type_set)):\n",
    "    for activation_i in range(len(activation_set)):\n",
    "        for w_init_i in range(len(w_init_set)):\n",
    "            \n",
    "            rnn_type = rnn_type_set[rnn_type_i]\n",
    "            activation = activation_set[activation_i]\n",
    "            w_init = w_init_set[w_init_i]\n",
    "\n",
    "            # make colormaps for plotting\n",
    "            if rnn_type=='LeakyRNN':\n",
    "                cmap = plt.get_cmap('terrain')\n",
    "            else:\n",
    "                cmap = plt.get_cmap('spring')\n",
    "\n",
    "            c = 'k'#cmap((w_init_i+1)*activation_i/(len(activation_set)*len(w_init_set)))\n",
    "            \n",
    "            # x-axis and labelling bs\n",
    "            x_ind_counter+=1\n",
    "            label = ' '.join([rnn_type,activation,w_init])\n",
    "            if len(ax1_xticks)==0:\n",
    "                ax1_xticks = [label,]\n",
    "            else:\n",
    "                ax1_xticks.append(label)\n",
    "\n",
    "            for seed in seed_set:\n",
    "            \n",
    "                m = os.path.join(p,data_folder,rnn_type,activation,w_init,n_tasks+'_tasks',n_rnn+'_n_rnn',\n",
    "                                 net_name,seed)\n",
    "                \n",
    "                #load performance data\n",
    "                fname = os.path.join(m, 'log.json')\n",
    "                with open(fname, 'r') as f:\n",
    "                    log_all = json.load(f)\n",
    "                    for r in range(len(rule_trains)):\n",
    "                        x = log_all['perf_' + rule_trains[r]]\n",
    "                        perf_ax.plot(x_ind_counter,x[-1],'o',alpha = al/10,c = c, markersize = 10)\n",
    "\n",
    "                #load atlas data\n",
    "                lesion_folder = 'lesion_fps_hierarchical_'+method+'_max_d'+str(max_d)\n",
    "                save_dir = os.path.join(m,lesion_folder)\n",
    "                cluster_var = np.load(os.path.join(save_dir,'cluster_var.npz'))\n",
    "                D = cluster_var['D'].T\n",
    "                feature_names_original = [cluster_var['tick_names'][s] for s in range(len(cluster_var['tick_names']))]\n",
    "\n",
    "                feat_order = [feature_names_original.index(s) for i,s in enumerate(feature_names_master)]\n",
    "                X = D[:,feat_order]\n",
    "                corr_mat = np.corrcoef(X.T)\n",
    "                \n",
    "                #calculate sparsity based on density of non-zero (below theshold) values\n",
    "                sparsity_metric_num = len_te*(np.float(n_rnn)-len(D))+np.sum(D.flatten()<sparsity_threshold)\n",
    "                sparsity_metric_denom = len_te*np.float(n_rnn)\n",
    "                sparsity_metric = sparsity_metric_num/sparsity_metric_denom\n",
    "                sparsity_ax.plot(x_ind_counter,sparsity_metric,'o',alpha = al,c = c, markersize = 10)\n",
    "\n",
    "                # only correlate lower triangle values to prevent arbitrary structure correlation (diag)\n",
    "                tril_corr_mat = corr_mat[np.tril_indices(len(corr_mat),-1)]\n",
    "                corr, pval = pearsonr(tril_corr_mat_master,tril_corr_mat)\n",
    "            \n",
    "                # plot correlation for single networks\n",
    "                corr_ax.plot(x_ind_counter,corr,'o',alpha = al,c = c, markersize = 10)\n",
    "\n",
    "                if seed==seed_set[0]:\n",
    "                    corr_mat_stack = corr_mat[:,np.newaxis]\n",
    "                else:\n",
    "                    corr_mat_stack = np.concatenate((corr_mat_stack,corr_mat[:,np.newaxis]),axis=1)\n",
    "            \n",
    "            corr_mat_ave = np.mean(corr_mat_stack,axis = 1)\n",
    "            tril_corr_mat_ave = corr_mat_ave[np.tril_indices(len(corr_mat_ave),-1)]\n",
    "            \n",
    "            # plot correlation for average networks\n",
    "            corr, pval = pearsonr(tril_corr_mat_master,tril_corr_mat_ave)\n",
    "            corr_ax.plot(x_ind_counter,corr,'o',c = c)\n",
    "            \n",
    "            # plot corr_mat examples\n",
    "            if x_ind_counter==ex_1:\n",
    "                plt.sca(corrmatex1)\n",
    "                ex_label = 'Example #1 \\n'\n",
    "            elif x_ind_counter==ex_2:\n",
    "                plt.sca(corrmatex2)\n",
    "                ex_label = 'Example #2 \\n'\n",
    "            elif x_ind_counter==ex_3:\n",
    "                plt.sca(corrmatex3)\n",
    "                ex_label = 'Example #3 \\n'\n",
    "\n",
    "            if x_ind_counter==ex_1 or x_ind_counter==ex_2 or x_ind_counter==ex_3:\n",
    "                plt.imshow(corr_mat_ave,cmap= 'Greys',clim = (-.5,1))\n",
    "                plt.title(ex_label+label, fontsize = 16)\n",
    "                if x_ind_counter==ex_3 and seed==seed_set[0]:\n",
    "                    cbar = plt.colorbar(orientation=\"horizontal\", ticks=[-1, 0, 1])\n",
    "                    cbar.set_label('Correlation Coefficient')\n",
    "\n",
    "            plt.ylabel('Task Periods')\n",
    "            plt.xlabel('Task Periods')\n",
    "            \n",
    "            corr_mat_stack = []\n",
    "\n",
    "# visualization beautification bs\n",
    "corr_ax.set_xticks(range(1,len(ax1_xticks)+1))\n",
    "corr_ax.set_xticklabels(ax1_xticks,rotation = 70,ha = 'right',fontsize = 14)\n",
    "corr_ax.set_ylabel('Correlation Coefficient')\n",
    "corr_ax.set_ylim((0,1.1))\n",
    "corr_ax.spines['top'].set_visible(False)\n",
    "corr_ax.spines['right'].set_visible(False)\n",
    "\n",
    "sparsity_ax.set_xticks(range(1,len(ax1_xticks)+1))\n",
    "sparsity_ax.set_xticklabels([])\n",
    "sparsity_ax.set_ylabel('Sparsity')\n",
    "sparsity_ax.spines['top'].set_visible(False)\n",
    "sparsity_ax.spines['right'].set_visible(False)\n",
    "\n",
    "perf_ax.set_xticks(range(1,len(ax1_xticks)+1))\n",
    "perf_ax.set_xticklabels([])\n",
    "perf_ax.set_ylabel('Performance')\n",
    "perf_ax.spines['top'].set_visible(False)\n",
    "perf_ax.spines['right'].set_visible(False)\n",
    "perf_ax.set_ylim((0,1.1))\n",
    "\n",
    "# vs_ax.set_xlabel('Master Correlation Matrix')\n",
    "# vs_ax.set_ylabel('Test Correlation Matrix')\n",
    "# vs_ax.spines['top'].set_visible(False)\n",
    "# vs_ax.spines['right'].set_visible(False)\n",
    "# vs_ax.set_aspect('equal')\n",
    "\n",
    "# corrmatex1.set_yticks(range(len_te))\n",
    "# corrmatex1.set_yticklabels(feature_names_master,fontsize = 10)\n",
    "\n",
    "plot_epoch_labels(corrmatex1,which_axes = 'xy')\n",
    "remove_ticks(corrmatex1)\n",
    "remove_spines(corrmatex1)\n",
    "\n",
    "plot_epoch_labels(corrmatex2,which_axes = 'xy')\n",
    "remove_ticks(corrmatex2)\n",
    "remove_spines(corrmatex2)\n",
    "\n",
    "plot_epoch_labels(corrmatex3,which_axes = 'xy')\n",
    "remove_ticks(corrmatex3)\n",
    "remove_spines(corrmatex3)\n",
    "\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
